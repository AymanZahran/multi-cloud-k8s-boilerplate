apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  labels:
    app: consul
    chart: consul-helm
    heritage: Helm
    release: consul
  name: consul-consul-server
  namespace: consul
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app: consul
      component: server
      release: consul
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: consul
    chart: consul-helm
    heritage: Helm
    release: consul
  name: consul-consul-client
  namespace: consul
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: consul
    chart: consul-helm
    heritage: Helm
    release: consul
  name: consul-consul-server
  namespace: consul
---
apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    app: consul
    chart: consul-helm
    heritage: Helm
    release: consul
  name: consul-consul-client-config
  namespace: consul
data:
  extra-from-values.json: "{}"
---
apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    app: consul
    chart: consul-helm
    heritage: Helm
    release: consul
  name: consul-consul-server-config
  namespace: consul
data:
  extra-from-values.json: "{}"
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  labels:
    app: consul
    chart: consul-helm
    heritage: Helm
    release: consul
  name: consul-consul-client
  namespace: consul
rules: []
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  labels:
    app: consul
    chart: consul-helm
    heritage: Helm
    release: consul
  name: consul-consul-server
  namespace: consul
rules: []
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    app: consul
    chart: consul-helm
    heritage: Helm
    release: consul
  name: consul-consul-client
  namespace: consul
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: consul-consul-client
subjects:
  - kind: ServiceAccount
    name: consul-consul-client
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    app: consul
    chart: consul-helm
    heritage: Helm
    release: consul
  name: consul-consul-server
  namespace: consul
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: consul-consul-server
subjects:
  - kind: ServiceAccount
    name: consul-consul-server
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: consul
    chart: consul-helm
    component: dns
    heritage: Helm
    release: consul
  name: consul-consul-dns
  namespace: consul
spec:
  ports:
    - name: dns-tcp
      port: 53
      protocol: TCP
      targetPort: dns-tcp
    - name: dns-udp
      port: 53
      protocol: UDP
      targetPort: dns-udp
  selector:
    app: consul
    hasDNS: "true"
    release: consul
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
  labels:
    app: consul
    chart: consul-helm
    component: server
    heritage: Helm
    release: consul
  name: consul-consul-server
  namespace: consul
spec:
  clusterIP: None
  ports:
    - name: http
      port: 8500
      targetPort: 8500
    - name: serflan-tcp
      port: 8301
      protocol: TCP
      targetPort: 8301
    - name: serflan-udp
      port: 8301
      protocol: UDP
      targetPort: 8301
    - name: serfwan-tcp
      port: 8302
      protocol: TCP
      targetPort: 8302
    - name: serfwan-udp
      port: 8302
      protocol: UDP
      targetPort: 8302
    - name: server
      port: 8300
      targetPort: 8300
    - name: dns-tcp
      port: 8600
      protocol: TCP
      targetPort: dns-tcp
    - name: dns-udp
      port: 8600
      protocol: UDP
      targetPort: dns-udp
  publishNotReadyAddresses: true
  selector:
    app: consul
    component: server
    release: consul
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: consul
    chart: consul-helm
    component: ui
    heritage: Helm
    release: consul
  name: consul-consul-ui
  namespace: consul
spec:
  ports:
    - name: http
      port: 80
      targetPort: 8500
  selector:
    app: consul
    component: server
    release: consul
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  labels:
    app: consul
    chart: consul-helm
    heritage: Helm
    release: consul
  name: consul-consul
  namespace: consul
spec:
  selector:
    matchLabels:
      app: consul
      chart: consul-helm
      component: client
      hasDNS: "true"
      release: consul
  template:
    metadata:
      annotations:
        consul.hashicorp.com/config-checksum: ca3d163bab055381827226140568f3bef7eaac187cebd76878e0b63e9e442356
        consul.hashicorp.com/connect-inject: "false"
      labels:
        app: consul
        chart: consul-helm
        component: client
        hasDNS: "true"
        release: consul
    spec:
      containers:
        - command:
            - /bin/sh
            - -ec
            - |
              CONSUL_FULLNAME="consul-consul"

              exec /bin/consul agent \
                -node="${NODE}" \
                -advertise="${ADVERTISE_IP}" \
                -bind=0.0.0.0 \
                -client=0.0.0.0 \
                -node-meta=pod-name:${HOSTNAME} \
                -hcl='leave_on_terminate = true' \
                -hcl='ports { grpc = 8502 }' \
                -config-dir=/consul/config \
                -datacenter=dc1 \
                -data-dir=/consul/data \
                -retry-join="${CONSUL_FULLNAME}-server-0.${CONSUL_FULLNAME}-server.${NAMESPACE}.svc" \
                -retry-join="${CONSUL_FULLNAME}-server-1.${CONSUL_FULLNAME}-server.${NAMESPACE}.svc" \
                -retry-join="${CONSUL_FULLNAME}-server-2.${CONSUL_FULLNAME}-server.${NAMESPACE}.svc" \
                -domain=consul
          env:
            - name: ADVERTISE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: NODE
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: HOST_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
          image: consul:1.8.4
          name: consul
          ports:
            - containerPort: 8500
              hostPort: 8500
              name: http
            - containerPort: 8502
              hostPort: 8502
              name: grpc
            - containerPort: 8301
              name: serflan-tcp
              protocol: TCP
            - containerPort: 8301
              name: serflan-udp
              protocol: UDP
            - containerPort: 8302
              name: serfwan
            - containerPort: 8300
              name: server
            - containerPort: 8600
              name: dns-tcp
              protocol: TCP
            - containerPort: 8600
              name: dns-udp
              protocol: UDP
          readinessProbe:
            exec:
              command:
                - /bin/sh
                - -ec
                - |
                  curl http://127.0.0.1:8500/v1/status/leader \
                  2>/dev/null | grep -E '".+"'
          resources:
            limits:
              cpu: 100m
              memory: 100Mi
            requests:
              cpu: 100m
              memory: 100Mi
          volumeMounts:
            - mountPath: /consul/data
              name: data
            - mountPath: /consul/config
              name: config
      serviceAccountName: consul-consul-client
      terminationGracePeriodSeconds: 10
      volumes:
        - emptyDir: {}
          name: data
        - configMap:
            name: consul-consul-client-config
          name: config
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app: consul
    chart: consul-helm
    component: server
    heritage: Helm
    release: consul
  name: consul-consul-server
  namespace: consul
spec:
  podManagementPolicy: Parallel
  replicas: 3
  selector:
    matchLabels:
      app: consul
      chart: consul-helm
      component: server
      hasDNS: "true"
      release: consul
  serviceName: consul-consul-server
  template:
    metadata:
      annotations:
        consul.hashicorp.com/config-checksum: ca3d163bab055381827226140568f3bef7eaac187cebd76878e0b63e9e442356
        consul.hashicorp.com/connect-inject: "false"
      labels:
        app: consul
        chart: consul-helm
        component: server
        hasDNS: "true"
        release: consul
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  app: consul
                  component: server
                  release: consul
              topologyKey: kubernetes.io/hostname
      containers:
        - command:
            - /bin/sh
            - -ec
            - |
              CONSUL_FULLNAME="consul-consul"

              exec /bin/consul agent \
                -advertise="${POD_IP}" \
                -bind=0.0.0.0 \
                -bootstrap-expect=3 \
                -client=0.0.0.0 \
                -config-dir=/consul/config \
                -datacenter=dc1 \
                -data-dir=/consul/data \
                -domain=consul \
                -hcl="connect { enabled = true }" \
                -ui \
                -retry-join=${CONSUL_FULLNAME}-server-0.${CONSUL_FULLNAME}-server.${NAMESPACE}.svc \
                -retry-join=${CONSUL_FULLNAME}-server-1.${CONSUL_FULLNAME}-server.${NAMESPACE}.svc \
                -retry-join=${CONSUL_FULLNAME}-server-2.${CONSUL_FULLNAME}-server.${NAMESPACE}.svc \
                -server
          env:
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          image: consul:1.8.4
          lifecycle:
            preStop:
              exec:
                command:
                  - /bin/sh
                  - -c
                  - consul leave
          name: consul
          ports:
            - containerPort: 8500
              name: http
            - containerPort: 8301
              name: serflan
            - containerPort: 8302
              name: serfwan
            - containerPort: 8300
              name: server
            - containerPort: 8600
              name: dns-tcp
              protocol: TCP
            - containerPort: 8600
              name: dns-udp
              protocol: UDP
          readinessProbe:
            exec:
              command:
                - /bin/sh
                - -ec
                - |
                  curl http://127.0.0.1:8500/v1/status/leader \
                  2>/dev/null | grep -E '".+"'
            failureThreshold: 2
            initialDelaySeconds: 5
            periodSeconds: 3
            successThreshold: 1
            timeoutSeconds: 5
          resources:
            limits:
              cpu: 100m
              memory: 100Mi
            requests:
              cpu: 100m
              memory: 100Mi
          volumeMounts:
            - mountPath: /consul/data
              name: data-consul
            - mountPath: /consul/config
              name: config
      securityContext:
        fsGroup: 1000
      serviceAccountName: consul-consul-server
      terminationGracePeriodSeconds: 30
      volumes:
        - configMap:
            name: consul-consul-server-config
          name: config
  volumeClaimTemplates:
    - metadata:
        name: data-consul
      spec:
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: 10Gi
---
apiVersion: v1
kind: Pod
metadata:
  annotations:
    helm.sh/hook: test-success
  labels:
    app: consul
    chart: consul-helm
    heritage: Helm
    release: consul
  name: consul-consul-test
  namespace: consul
spec:
  containers:
    - command:
        - /bin/sh
        - -ec
        - |
          consul members | tee members.txt
          if [ $(grep -c consul-server members.txt) != $(grep consul-server members.txt | grep -c alive) ]
          then
            echo "Failed because not all consul servers are available"
            exit 1
          fi
      env:
        - name: HOST_IP
          valueFrom:
            fieldRef:
              fieldPath: status.hostIP
        - name: CONSUL_HTTP_ADDR
          value: http://$(HOST_IP):8500
      image: consul:1.8.4
      name: consul-test
  restartPolicy: Never
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/instance: vault
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: vault-agent-injector
  name: vault-agent-injector
  namespace: vault
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/instance: vault
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: vault
    helm.sh/chart: vault-0.25.0
  name: vault
  namespace: vault
---
apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/instance: vault
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: vault
    helm.sh/chart: vault-0.25.0
  name: vault-config
  namespace: vault
data:
  extraconfig-from-values.hcl: |-
    disable_mlock = true
    ui = true

    listener "tcp" {
      tls_disable = 1
      address = "[::]:8200"
      cluster_address = "[::]:8201"
      # Enable unauthenticated metrics access (necessary for Prometheus Operator)
      #telemetry {
      #  unauthenticated_metrics_access = "true"
      #}
    }
    storage "file" {
      path = "/vault/data"
    }

    # Example configuration for using auto-unseal, using Google Cloud KMS. The
    # GKMS keys must already exist, and the cluster must have a service account
    # that is authorized to access GCP KMS.
    #seal "gcpckms" {
    #   project     = "vault-helm-dev"
    #   region      = "global"
    #   key_ring    = "vault-helm-unseal-kr"
    #   crypto_key  = "vault-helm-unseal-key"
    #}

    # Example configuration for enabling Prometheus metrics in your config.
    #telemetry {
    #  prometheus_retention_time = "30s"
    #  disable_hostname = true
    #}
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/instance: vault
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: vault-agent-injector
  name: vault-agent-injector-clusterrole
rules:
  - apiGroups:
      - admissionregistration.k8s.io
    resources:
      - mutatingwebhookconfigurations
    verbs:
      - get
      - list
      - watch
      - patch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/instance: vault
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: vault-agent-injector
  name: vault-agent-injector-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: vault-agent-injector-clusterrole
subjects:
  - kind: ServiceAccount
    name: vault-agent-injector
    namespace: vault
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/instance: vault
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: vault
    helm.sh/chart: vault-0.25.0
  name: vault-server-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:auth-delegator
subjects:
  - kind: ServiceAccount
    name: vault
    namespace: vault
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: vault
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: vault-agent-injector
  name: vault-agent-injector-svc
  namespace: vault
spec:
  ports:
    - name: https
      port: 443
      targetPort: 8080
  selector:
    app.kubernetes.io/instance: vault
    app.kubernetes.io/name: vault-agent-injector
    component: webhook
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: vault
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: vault
    helm.sh/chart: vault-0.25.0
    vault-internal: "true"
  name: vault-internal
  namespace: vault
spec:
  clusterIP: None
  ports:
    - name: http
      port: 8200
      targetPort: 8200
    - name: https-internal
      port: 8201
      targetPort: 8201
  publishNotReadyAddresses: true
  selector:
    app.kubernetes.io/instance: vault
    app.kubernetes.io/name: vault
    component: server
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: vault
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: vault
    helm.sh/chart: vault-0.25.0
  name: vault
  namespace: vault
spec:
  ports:
    - name: http
      port: 8200
      targetPort: 8200
    - name: https-internal
      port: 8201
      targetPort: 8201
  publishNotReadyAddresses: true
  selector:
    app.kubernetes.io/instance: vault
    app.kubernetes.io/name: vault
    component: server
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/instance: vault
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: vault-agent-injector
    component: webhook
  name: vault-agent-injector
  namespace: vault
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: vault
      app.kubernetes.io/name: vault-agent-injector
      component: webhook
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: vault
        app.kubernetes.io/name: vault-agent-injector
        component: webhook
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  app.kubernetes.io/instance: vault
                  app.kubernetes.io/name: vault-agent-injector
                  component: webhook
              topologyKey: kubernetes.io/hostname
      containers:
        - args:
            - agent-inject
            - 2>&1
          env:
            - name: AGENT_INJECT_LISTEN
              value: :8080
            - name: AGENT_INJECT_LOG_LEVEL
              value: info
            - name: AGENT_INJECT_VAULT_ADDR
              value: http://vault.vault.svc:8200
            - name: AGENT_INJECT_VAULT_AUTH_PATH
              value: auth/kubernetes
            - name: AGENT_INJECT_VAULT_IMAGE
              value: hashicorp/vault:1.14.0
            - name: AGENT_INJECT_TLS_AUTO
              value: vault-agent-injector-cfg
            - name: AGENT_INJECT_TLS_AUTO_HOSTS
              value: vault-agent-injector-svc,vault-agent-injector-svc.vault,vault-agent-injector-svc.vault.svc
            - name: AGENT_INJECT_LOG_FORMAT
              value: standard
            - name: AGENT_INJECT_REVOKE_ON_SHUTDOWN
              value: "false"
            - name: AGENT_INJECT_CPU_REQUEST
              value: 250m
            - name: AGENT_INJECT_CPU_LIMIT
              value: 500m
            - name: AGENT_INJECT_MEM_REQUEST
              value: 64Mi
            - name: AGENT_INJECT_MEM_LIMIT
              value: 128Mi
            - name: AGENT_INJECT_DEFAULT_TEMPLATE
              value: map
            - name: AGENT_INJECT_TEMPLATE_CONFIG_EXIT_ON_RETRY_FAILURE
              value: "true"
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
          image: hashicorp/vault-k8s:1.2.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 2
            httpGet:
              path: /health/ready
              port: 8080
              scheme: HTTPS
            initialDelaySeconds: 5
            periodSeconds: 2
            successThreshold: 1
            timeoutSeconds: 5
          name: sidecar-injector
          readinessProbe:
            failureThreshold: 2
            httpGet:
              path: /health/ready
              port: 8080
              scheme: HTTPS
            initialDelaySeconds: 5
            periodSeconds: 2
            successThreshold: 1
            timeoutSeconds: 5
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
          startupProbe:
            failureThreshold: 12
            httpGet:
              path: /health/ready
              port: 8080
              scheme: HTTPS
            initialDelaySeconds: 5
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 5
      hostNetwork: false
      securityContext:
        fsGroup: 1000
        runAsGroup: 1000
        runAsNonRoot: true
        runAsUser: 100
      serviceAccountName: vault-agent-injector
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app.kubernetes.io/instance: vault
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: vault
  name: vault
  namespace: vault
spec:
  podManagementPolicy: Parallel
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: vault
      app.kubernetes.io/name: vault
      component: server
  serviceName: vault-internal
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: vault
        app.kubernetes.io/name: vault
        component: server
        helm.sh/chart: vault-0.25.0
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  app.kubernetes.io/instance: vault
                  app.kubernetes.io/name: vault
                  component: server
              topologyKey: kubernetes.io/hostname
      containers:
        - args:
            - |
              cp /vault/config/extraconfig-from-values.hcl /tmp/storageconfig.hcl;
              [ -n "${HOST_IP}" ] && sed -Ei "s|HOST_IP|${HOST_IP?}|g" /tmp/storageconfig.hcl;
              [ -n "${POD_IP}" ] && sed -Ei "s|POD_IP|${POD_IP?}|g" /tmp/storageconfig.hcl;
              [ -n "${HOSTNAME}" ] && sed -Ei "s|HOSTNAME|${HOSTNAME?}|g" /tmp/storageconfig.hcl;
              [ -n "${API_ADDR}" ] && sed -Ei "s|API_ADDR|${API_ADDR?}|g" /tmp/storageconfig.hcl;
              [ -n "${TRANSIT_ADDR}" ] && sed -Ei "s|TRANSIT_ADDR|${TRANSIT_ADDR?}|g" /tmp/storageconfig.hcl;
              [ -n "${RAFT_ADDR}" ] && sed -Ei "s|RAFT_ADDR|${RAFT_ADDR?}|g" /tmp/storageconfig.hcl;
              /usr/local/bin/docker-entrypoint.sh vault server -config=/tmp/storageconfig.hcl 
          command:
            - /bin/sh
            - -ec
          env:
            - name: HOST_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: VAULT_K8S_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: VAULT_K8S_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: VAULT_ADDR
              value: http://127.0.0.1:8200
            - name: VAULT_API_ADDR
              value: http://$(POD_IP):8200
            - name: SKIP_CHOWN
              value: "true"
            - name: SKIP_SETCAP
              value: "true"
            - name: HOSTNAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: VAULT_CLUSTER_ADDR
              value: https://$(HOSTNAME).vault-internal:8201
            - name: HOME
              value: /home/vault
          image: hashicorp/vault:1.14.0
          imagePullPolicy: IfNotPresent
          lifecycle:
            preStop:
              exec:
                command:
                  - /bin/sh
                  - -c
                  - sleep 5 && kill -SIGTERM $(pidof vault)
          name: vault
          ports:
            - containerPort: 8200
              name: http
            - containerPort: 8201
              name: https-internal
            - containerPort: 8202
              name: http-rep
          readinessProbe:
            exec:
              command:
                - /bin/sh
                - -ec
                - vault status -tls-skip-verify
            failureThreshold: 2
            initialDelaySeconds: 5
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 3
          securityContext:
            allowPrivilegeEscalation: false
          volumeMounts:
            - mountPath: /vault/data
              name: data
            - mountPath: /vault/config
              name: config
            - mountPath: /home/vault
              name: home
      hostNetwork: false
      securityContext:
        fsGroup: 1000
        runAsGroup: 1000
        runAsNonRoot: true
        runAsUser: 100
      serviceAccountName: vault
      terminationGracePeriodSeconds: 10
      volumes:
        - configMap:
            name: vault-config
          name: config
        - emptyDir: {}
          name: home
  updateStrategy:
    type: OnDelete
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: 10Gi
---
apiVersion: admissionregistration.k8s.io/v1
kind: MutatingWebhookConfiguration
metadata:
  labels:
    app.kubernetes.io/instance: vault
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: vault-agent-injector
  name: vault-agent-injector-cfg
webhooks:
  - admissionReviewVersions:
      - v1
      - v1beta1
    clientConfig:
      caBundle: ""
      service:
        name: vault-agent-injector-svc
        namespace: vault
        path: /mutate
    failurePolicy: Ignore
    matchPolicy: Exact
    name: vault.hashicorp.com
    objectSelector:
      matchExpressions:
        - key: app.kubernetes.io/name
          operator: NotIn
          values:
            - vault-agent-injector
    rules:
      - apiGroups:
          - ""
        apiVersions:
          - v1
        operations:
          - CREATE
          - UPDATE
        resources:
          - pods
    sideEffects: None
    timeoutSeconds: 30
---
apiVersion: v1
kind: Pod
metadata:
  annotations:
    helm.sh/hook: test
  name: vault-server-test
  namespace: vault
spec:
  containers:
    - command:
        - /bin/sh
        - -c
        - |
          echo "Checking for sealed info in 'vault status' output"
          ATTEMPTS=10
          n=0
          until [ "$n" -ge $ATTEMPTS ]
          do
            echo "Attempt" $n...
            vault status -format yaml | grep -E '^sealed: (true|false)' && break
            n=$((n+1))
            sleep 5
          done
          if [ $n -ge $ATTEMPTS ]; then
            echo "timed out looking for sealed info in 'vault status' output"
            exit 1
          fi

          exit 0
      env:
        - name: VAULT_ADDR
          value: http://vault.vault.svc:8200
      image: hashicorp/vault:1.14.0
      imagePullPolicy: IfNotPresent
      name: vault-server-test
  restartPolicy: Never
